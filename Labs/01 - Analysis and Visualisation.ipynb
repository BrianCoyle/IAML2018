{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Data analysis and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we work with a spam filtering dataset. We will perform exploratory data analysis, visualisation and, finally, we learn how to perform classification tasks using Naive Bayes. For this, we will use the the packages introduced in Lab 1, and `scikit-learn` package (`sklearn`): a machine learning library for Python which works with numpy array, and pandas DataFrame objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please Note**: Throughout this lab we make reference to [`methods`](https://en.wikipedia.org/wiki/Method_%28computer_programming%29) for specific objects e.g. \"make use of the predict method of the MultinomialNB classifier\". If you get confused, refer to the documentation and just ctrl+f for the object concerned:\n",
    "* [Scikit-learn API documentation](http://scikit-learn.org/0.19/modules/classes.html) \n",
    "* [Seaborn API documentation](https://seaborn.github.io/api.html)\n",
    "* [Matplotlib Pyplot documentation](http://matplotlib.org/2.2.3/api/pyplot_summary.html)\n",
    "* [Pandas API documentation](http://pandas.pydata.org/pandas-docs/version/0.23.4/api.html)\n",
    "* [Numpy documentation](https://docs.scipy.org/doc/numpy-1.15.0/reference/)\n",
    "\n",
    "There are also tonnes of great examples online; googling key words with the word \"example\" will serve you well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the packages (run all the code cells as you read along):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Clarification*:\n",
    "\n",
    "* The `%matplotlib inline` command is a special ipython [built in magic command](http://ipython.readthedocs.io/en/stable/interactive/magics.html) which forces the matplotlib plots to be rendered within the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spambase dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Spambase](http://archive.ics.uci.edu/ml/datasets/Spambase) dataset consists of tagged emails from a single email account. You should read through the description available for this data to get a feel for what you're dealing with. We have downloaded the dataset for you.\n",
    "\n",
    "You will find the dataset located at `./datasets/spambase.csv` (the `datasets` directory is adjacent to this file). Execute the cell below to load the csv into in a pandas DataFrame object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'spambase.csv')\n",
    "spambase = pd.read_csv(data_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now loaded the data. Let's get a feeling of what the data looks like by using the `head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2259.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail   ...     char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00   ...            0.00        0.000   \n",
       "1             0.00            0.94   ...            0.00        0.132   \n",
       "2             0.64            0.25   ...            0.01        0.143   \n",
       "3             0.31            0.63   ...            0.00        0.137   \n",
       "4             0.31            0.63   ...            0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                        61.0   \n",
       "1                       5.114                       101.0   \n",
       "2                       9.821                       485.0   \n",
       "3                       3.537                        40.0   \n",
       "4                       3.537                        40.0   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                     278.0      1.0  \n",
       "1                    1028.0      1.0  \n",
       "2                    2259.0      1.0  \n",
       "3                     191.0      1.0  \n",
       "4                     191.0      1.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase.head(5) # Display the 5 first rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Display the number of attributes in the dataset (i.e. number of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "spambase.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Display the number of observations (i.e. number of rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "spambase.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Display the mean and standard deviation of each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute: word_freq_make  Mean:  0.10455335796565962  Standard Dev:  0.3053243763947285\n",
      "Attribute: word_freq_address  Mean:  0.21301456205172783  Standard Dev:  1.290434933900888\n",
      "Attribute: word_freq_all  Mean:  0.2806563790480323  Standard Dev:  0.5040880946404874\n",
      "Attribute: word_freq_3d  Mean:  0.06542490762877635  Standard Dev:  1.3949997483252192\n",
      "Attribute: word_freq_our  Mean:  0.3122234296891974  Standard Dev:  0.6724396819868041\n",
      "Attribute: word_freq_over  Mean:  0.09590089111062813  Standard Dev:  0.2737943243743938\n",
      "Attribute: word_freq_remove  Mean:  0.11420778091719185  Standard Dev:  0.3913988137131612\n",
      "Attribute: word_freq_internet  Mean:  0.10529450119539223  Standard Dev:  0.40102786485706676\n",
      "Attribute: word_freq_order  Mean:  0.0900673766572484  Standard Dev:  0.2785855848455536\n",
      "Attribute: word_freq_mail  Mean:  0.23941317104977197  Standard Dev:  0.6446853287674577\n",
      "Attribute: word_freq_receive  Mean:  0.05982395131493154  Standard Dev:  0.2015227605968929\n",
      "Attribute: word_freq_will  Mean:  0.5417018039556623  Standard Dev:  0.8616048236718237\n",
      "Attribute: word_freq_people  Mean:  0.09392958052597254  Standard Dev:  0.30100308763596195\n",
      "Attribute: word_freq_report  Mean:  0.058626385568354686  Standard Dev:  0.335147402669881\n",
      "Attribute: word_freq_addresses  Mean:  0.04920452075635739  Standard Dev:  0.2588153207513001\n",
      "Attribute: word_freq_free  Mean:  0.24884807650510785  Standard Dev:  0.8257019557935116\n",
      "Attribute: word_freq_business  Mean:  0.14258639426211697  Standard Dev:  0.4440070699667222\n",
      "Attribute: word_freq_email  Mean:  0.18474462073462303  Standard Dev:  0.5310647007198648\n",
      "Attribute: word_freq_you  Mean:  1.6620995435774817  Standard Dev:  1.775287709196947\n",
      "Attribute: word_freq_credit  Mean:  0.08557704846772435  Standard Dev:  0.5097114885413496\n",
      "Attribute: word_freq_your  Mean:  0.8097609215387966  Standard Dev:  1.2006793100979438\n",
      "Attribute: word_freq_font  Mean:  0.12120191262768967  Standard Dev:  1.0256441144336699\n",
      "Attribute: word_freq_000  Mean:  0.10164529450119543  Standard Dev:  0.3502483501539927\n",
      "Attribute: word_freq_money  Mean:  0.0942686372527711  Standard Dev:  0.44258742205411283\n",
      "Attribute: word_freq_hp  Mean:  0.5495044555531406  Standard Dev:  1.6711677034900754\n",
      "Attribute: word_freq_hpl  Mean:  0.2653836122582047  Standard Dev:  0.8868589453473005\n",
      "Attribute: word_freq_george  Mean:  0.767304933710063  Standard Dev:  3.3669258521388645\n",
      "Attribute: word_freq_650  Mean:  0.12484459900021724  Standard Dev:  0.5385175126894329\n",
      "Attribute: word_freq_lab  Mean:  0.09891545316235598  Standard Dev:  0.5932621182130078\n",
      "Attribute: word_freq_labs  Mean:  0.10285155400999778  Standard Dev:  0.45663192172104455\n",
      "Attribute: word_freq_telnet  Mean:  0.06475331449684846  Standard Dev:  0.40334866104024825\n",
      "Attribute: word_freq_857  Mean:  0.04704846772440773  Standard Dev:  0.3285231745896845\n",
      "Attribute: word_freq_data  Mean:  0.09722886329058895  Standard Dev:  0.5558467888597739\n",
      "Attribute: word_freq_415  Mean:  0.04783525320582481  Standard Dev:  0.32940952722596467\n",
      "Attribute: word_freq_85  Mean:  0.10541186698543797  Standard Dev:  0.5322020304339322\n",
      "Attribute: word_freq_technology  Mean:  0.09747663551401871  Standard Dev:  0.4025793828224043\n",
      "Attribute: word_freq_1999  Mean:  0.1369528363399261  Standard Dev:  0.4234053476375298\n",
      "Attribute: word_freq_parts  Mean:  0.013201477939578352  Standard Dev:  0.22062680768649276\n",
      "Attribute: word_freq_pm  Mean:  0.0786285590089111  Standard Dev:  0.4346248125831785\n",
      "Attribute: word_freq_direct  Mean:  0.06483373179743535  Standard Dev:  0.34987795487716794\n",
      "Attribute: word_freq_cs  Mean:  0.04366659421864813  Standard Dev:  0.36116544567142106\n",
      "Attribute: word_freq_meeting  Mean:  0.13233862203868724  Standard Dev:  0.7667361022366807\n",
      "Attribute: word_freq_original  Mean:  0.0460986742012606  Standard Dev:  0.22378745272065964\n",
      "Attribute: word_freq_project  Mean:  0.07919582699413176  Standard Dev:  0.621907978483419\n",
      "Attribute: word_freq_re  Mean:  0.3012236470332536  Standard Dev:  1.0115772792026239\n",
      "Attribute: word_freq_edu  Mean:  0.1798239513149317  Standard Dev:  0.9110200446273338\n",
      "Attribute: word_freq_table  Mean:  0.005444468593783961  Standard Dev:  0.07626598130715481\n",
      "Attribute: word_freq_conference  Mean:  0.03186915887850466  Standard Dev:  0.2857035932458345\n",
      "Attribute: char_freq_;  Mean:  0.038574657683112336  Standard Dev:  0.24344486796690443\n",
      "Attribute: char_freq_(  Mean:  0.13903042816778938  Standard Dev:  0.270325992251046\n",
      "Attribute: char_freq_[  Mean:  0.01697587480982397  Standard Dev:  0.10938227525117342\n",
      "Attribute: char_freq_!  Mean:  0.26907085416213833  Standard Dev:  0.8155829855805651\n",
      "Attribute: char_freq_$  Mean:  0.07581069332753756  Standard Dev:  0.2458552893960734\n",
      "Attribute: char_freq_#  Mean:  0.04423820908498153  Standard Dev:  0.4292954279114892\n",
      "Attribute: capital_run_length_average  Mean:  5.19151510541188  Standard Dev:  31.72600044929807\n",
      "Attribute: capital_run_length_longest  Mean:  52.17278852423386  Standard Dev:  194.87012914173107\n",
      "Attribute: capital_run_length_total  Mean:  283.28928493805694  Standard Dev:  606.2819540935897\n",
      "Attribute: is_spam  Mean:  0.39404477287546186  Standard Dev:  0.48864454345159236\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes her\n",
    "\n",
    "for key in list(spambase.keys()):\n",
    "    print('Attribute:', key, ' Mean: ', np.mean(spambase[key]), ' Standard Dev: ', np.std(spambase[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to *remove* some of the attributes from our data. There are various reasons for wanting to do so, for instance we might think that these are not relevant to the task we want to perform (i.e. e-mail classification) or they might have been contaminated with noise during the data collection process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Delete the `capital_run_length_average`, `capital_run_length_longest` and  `capital_run_length_total` attributes. \n",
    "*Hint*: You should make use of the [`drop`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) method. \n",
    "\n",
    "*Tip*: some pandas methods have the argument `inplace` which you can use to determine whether they alter the object they are called upon and return nothing, or return a new object. This is particularly useful if you are dealing with huge datasets where you would typically want to operate `inplace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n",
    "spambase = spambase.drop(columns=['capital_run_length_average','capital_run_length_longest', 'capital_run_length_total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Display the new number of attributes. Does it look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 55)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "spambase.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining attributes represent relative frequencies of various important words and characters in emails. This is true for all attributes except `is_spam` which represents whether the e-mail was annotated as spam or not. So each e-mail is represented by a 55 dimensional vector representing whether or not a particular word exists in an e-mail. This is the so called [bag of words](http://en.wikipedia.org/wiki/Bag_of_words_model) representation and is clearly a very crude approximation since it does not take into account the order of the words in the emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a feeling of the distribution of ham (i.e. valid) vs. spam emails. We can do this by using a [countplot](https://seaborn.github.io/generated/seaborn.countplot.html?highlight=countplot#seaborn.countplot) in seaborn. In the code cell below, write code to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Produce a seaborn [countplot](https://seaborn.github.io/generated/seaborn.countplot.html?highlight=countplot#seaborn.countplot) object that shows the distribution of ham/spam e-mails. Assign it to a variable (e.g. `ax` to emphasise it is a [matplotlib.axes.Axes](https://matplotlib.org/2.2.3/api/axes_api.html) object)\n",
    "  \n",
    "**b)** In the same cell, modify the labels on the x axis (`xticklabels`) to `Ham` and `Spam` (by default they should be set to `0.0` and `1.0`). *Hint: Axes objects have a [`set_xticklabels`](https://matplotlib.org/2.2.3/api/_as_gen/matplotlib.axes.Axes.set_xticklabels.html#matplotlib.axes.Axes.set_xticklabels) method!* \n",
    "  \n",
    "**c)** Finally, again in the same cell, remove the `is_spam` label from the x axis (`xlabel`) since it does not add any information to the graph\n",
    "\n",
    "You may notice `<matplotlib.text.Text at ...memory_location...>` printed by the ipython notebook. This is just because the notebook is inferring how to display the last object in the cell. To explicitly plot the Axes object, use the `matplotlib.pyplot.show()` method at the very end of the cell, i.e. `plt.show()` (we imported the `matplotlib.pyplot` module as `plt` above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "# x = np.sum(spambase['is_spam'])\n",
    "# y = spambase.shape[0] - x\n",
    "# freq = [x/spambase.shape[0], y/spambase.shape[0]]\n",
    "# freq_label = ['Spam', 'Not Spam']\n",
    "# sns.countplot(freq_label, freq)\n",
    "ax = sns.countplot(x=\"is_spam\", data=spambase);\n",
    "ax.set_xticklabels(['Spam', 'Ham'])\n",
    "ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to simplify the problem by transforming our dataset. We will replace all numerical values which represent word frequencies with a binary value representing whether each word was present in a document or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 4 ==========\n",
    "\n",
    "**a)** Crate a new dataframe called `spambase_binary` from `spambase`. *Hint*: Look into the [`copy`](http://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.copy.html) method in pandas. \n",
    "\n",
    "*Tip*: Be careful, in python, unless you explictly say not to, assigment is typically just reference e.g.\n",
    "```python\n",
    "i = [1, 3]\n",
    "j = i\n",
    "i[1] = 5\n",
    "print(j)\n",
    "```\n",
    "outputs:\n",
    "```\n",
    "[1, 5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "spambase_binary = spambase.copy()\n",
    "len(spambase_binary)\n",
    "# spambase_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Convert all attributes in `spambase_binary` to Boolean values: 1 if the word or character is present in the email, or 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n",
    "spambase_binary.head(5)\n",
    "for attribute in list(spambase_binary.keys()):\n",
    "    for email in range(0, len(spambase_binary)):\n",
    "        if spambase_binary[attribute][email] > 0:\n",
    "            spambase_binary[attribute][email] = 1\n",
    "        else:\n",
    "            spambase_binary[attribute][email] = 0\n",
    "# spambase_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Display the 5 last observations of the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n",
    "spambase_binary.head(5)\n",
    "true_labels = spambase_binary['is_spam']\n",
    "# true_labels\n",
    "# spambase.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get a feeling for how the presence or absence of some specific words could affect the outcome (whether an email is classifed as *ham* or *spam*). We will be focusing on three specific words, namely `make`, `internet` and `edu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 5 ==========\n",
    "\n",
    "**a)** Using seaborn, produce one figure with three [countplots](https://seaborn.github.io/generated/seaborn.countplot.html?highlight=countplot#seaborn.countplot), one for each of the frequency variables for the words `make`, `internet` and `edu`. For each variable, the count plot should have two bars: the number of emails containing the word (i.e. the variable = 1), and the number not containing that word (i.e. the variable = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "f, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
    "axes[0][0] = sns.countplot(x='word_freq_internet', hue = 'is_spam', data = spambase_binary, ax=axes[0][0])\n",
    "\n",
    "axes[0][1] = sns.countplot(x='word_freq_make',hue = 'is_spam', data = spambase_binary, ax=axes[0][1])\n",
    "axes[1][0] = sns.countplot(x='word_freq_edu', hue = 'is_spam', data = spambase_binary, ax=axes[1][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Repeat the above but split the bars showing the proportion of emails that are spam/ham. *Hint*: This only requires you to use the `hue` input argument to use different colours for the `is_spam` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the transformed dataset, we now wish to train a NaÃ¯ve Bayes classifier to distinguish spam from regular email by fitting a distribution of the number of occurrences of each word for all the spam and non-spam e-mails. Read about the [Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) and the underlying assumption if you are not already familiar with it. In this lab we focus on the [Multinomial Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes). \n",
    "\n",
    "We will make use of the `MultinomialNB` class in `sklearn`. **Check out the user guide [description](http://scikit-learn.org/0.19/modules/naive_bayes.html#multinomial-naive-bayes) and [documentation](http://scikit-learn.org/0.19/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) to familiarise yourself with this class.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All classifiers in `sklearn` implement a `fit()` and `predict()` [method](https://en.wikipedia.org/wiki/Method_%28computer_programming%29). The first learns the parameters of the model and the latter classifies inputs. For a Naive Bayes classifier, the [`fit`](http://scikit-learn.org/0.19/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit) method takes at least two input arguments `X` and `y`, where `X` are the input features and `y` are the labels associated with each example in the training dataset (i.e. targets). \n",
    "\n",
    "As a first step we extract the input features and targets from the DataFrame. To do so, we will use the [`values`](http://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.values.html) property. For the input features we want to select all columns except `is_spam` and for this we may use the [`drop`](http://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.drop.html) method which discards the specified columns along the given axis. In fact, we can combine these two operations in one step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 6 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Create a Pandas DataFrame object `X` containing only the features (i.e. exclude the label `is_spam`). We need to do this as it is the input Scikit-learn objects expect for fitting. *Hint*: make use of the `drop` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_re</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4593</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0                0.0                1.0            1.0           0.0   \n",
       "1                1.0                1.0            1.0           0.0   \n",
       "2                1.0                0.0            1.0           0.0   \n",
       "3                0.0                0.0            0.0           0.0   \n",
       "4                0.0                0.0            0.0           0.0   \n",
       "5                0.0                0.0            0.0           0.0   \n",
       "6                0.0                0.0            0.0           0.0   \n",
       "7                0.0                0.0            0.0           0.0   \n",
       "8                1.0                0.0            1.0           0.0   \n",
       "9                1.0                1.0            1.0           0.0   \n",
       "10               0.0                0.0            0.0           0.0   \n",
       "11               0.0                0.0            1.0           0.0   \n",
       "12               0.0                1.0            1.0           0.0   \n",
       "13               0.0                0.0            0.0           0.0   \n",
       "14               0.0                0.0            1.0           0.0   \n",
       "15               0.0                1.0            1.0           0.0   \n",
       "16               0.0                0.0            0.0           0.0   \n",
       "17               0.0                0.0            0.0           0.0   \n",
       "18               0.0                0.0            1.0           0.0   \n",
       "19               0.0                1.0            0.0           0.0   \n",
       "20               0.0                0.0            0.0           0.0   \n",
       "21               1.0                1.0            1.0           0.0   \n",
       "22               0.0                0.0            0.0           0.0   \n",
       "23               0.0                0.0            0.0           0.0   \n",
       "24               0.0                0.0            0.0           0.0   \n",
       "25               1.0                1.0            1.0           0.0   \n",
       "26               0.0                0.0            0.0           0.0   \n",
       "27               0.0                0.0            0.0           0.0   \n",
       "28               0.0                0.0            0.0           0.0   \n",
       "29               0.0                0.0            0.0           0.0   \n",
       "...              ...                ...            ...           ...   \n",
       "4571             0.0                0.0            1.0           0.0   \n",
       "4572             0.0                0.0            0.0           0.0   \n",
       "4573             0.0                0.0            1.0           0.0   \n",
       "4574             1.0                0.0            1.0           0.0   \n",
       "4575             0.0                0.0            0.0           0.0   \n",
       "4576             0.0                0.0            0.0           0.0   \n",
       "4577             0.0                0.0            1.0           0.0   \n",
       "4578             0.0                0.0            1.0           0.0   \n",
       "4579             1.0                1.0            1.0           0.0   \n",
       "4580             0.0                0.0            0.0           0.0   \n",
       "4581             0.0                0.0            0.0           0.0   \n",
       "4582             0.0                0.0            0.0           0.0   \n",
       "4583             0.0                0.0            1.0           0.0   \n",
       "4584             0.0                0.0            1.0           0.0   \n",
       "4585             0.0                0.0            0.0           0.0   \n",
       "4586             0.0                0.0            0.0           0.0   \n",
       "4587             0.0                0.0            0.0           0.0   \n",
       "4588             0.0                0.0            1.0           0.0   \n",
       "4589             0.0                0.0            0.0           0.0   \n",
       "4590             0.0                0.0            0.0           0.0   \n",
       "4591             0.0                0.0            0.0           0.0   \n",
       "4592             0.0                0.0            1.0           0.0   \n",
       "4593             0.0                0.0            0.0           0.0   \n",
       "4594             0.0                0.0            0.0           0.0   \n",
       "4595             0.0                0.0            1.0           0.0   \n",
       "4596             1.0                0.0            1.0           0.0   \n",
       "4597             0.0                0.0            0.0           0.0   \n",
       "4598             1.0                0.0            1.0           0.0   \n",
       "4599             1.0                0.0            0.0           0.0   \n",
       "4600             0.0                0.0            1.0           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0               1.0             0.0               0.0                 0.0   \n",
       "1               1.0             1.0               1.0                 1.0   \n",
       "2               1.0             1.0               1.0                 1.0   \n",
       "3               1.0             0.0               1.0                 1.0   \n",
       "4               1.0             0.0               1.0                 1.0   \n",
       "5               1.0             0.0               0.0                 1.0   \n",
       "6               1.0             0.0               0.0                 0.0   \n",
       "7               1.0             0.0               0.0                 1.0   \n",
       "8               1.0             0.0               1.0                 0.0   \n",
       "9               1.0             1.0               1.0                 0.0   \n",
       "10              0.0             0.0               1.0                 0.0   \n",
       "11              1.0             1.0               1.0                 0.0   \n",
       "12              1.0             0.0               0.0                 0.0   \n",
       "13              1.0             0.0               1.0                 0.0   \n",
       "14              1.0             1.0               0.0                 1.0   \n",
       "15              1.0             0.0               1.0                 0.0   \n",
       "16              1.0             0.0               0.0                 0.0   \n",
       "17              0.0             0.0               0.0                 0.0   \n",
       "18              1.0             0.0               1.0                 0.0   \n",
       "19              1.0             1.0               0.0                 0.0   \n",
       "20              0.0             0.0               0.0                 0.0   \n",
       "21              1.0             1.0               1.0                 1.0   \n",
       "22              1.0             0.0               0.0                 0.0   \n",
       "23              1.0             0.0               0.0                 0.0   \n",
       "24              0.0             0.0               0.0                 0.0   \n",
       "25              1.0             1.0               1.0                 1.0   \n",
       "26              0.0             0.0               0.0                 0.0   \n",
       "27              0.0             0.0               1.0                 0.0   \n",
       "28              0.0             0.0               0.0                 0.0   \n",
       "29              1.0             0.0               1.0                 0.0   \n",
       "...             ...             ...               ...                 ...   \n",
       "4571            1.0             1.0               0.0                 0.0   \n",
       "4572            0.0             0.0               0.0                 0.0   \n",
       "4573            1.0             1.0               0.0                 0.0   \n",
       "4574            0.0             0.0               0.0                 0.0   \n",
       "4575            0.0             0.0               0.0                 0.0   \n",
       "4576            0.0             0.0               0.0                 0.0   \n",
       "4577            0.0             0.0               0.0                 0.0   \n",
       "4578            0.0             0.0               0.0                 0.0   \n",
       "4579            0.0             0.0               0.0                 0.0   \n",
       "4580            0.0             0.0               0.0                 0.0   \n",
       "4581            0.0             1.0               0.0                 0.0   \n",
       "4582            0.0             0.0               0.0                 0.0   \n",
       "4583            0.0             0.0               0.0                 0.0   \n",
       "4584            0.0             1.0               0.0                 0.0   \n",
       "4585            0.0             0.0               0.0                 0.0   \n",
       "4586            1.0             0.0               0.0                 0.0   \n",
       "4587            0.0             0.0               0.0                 0.0   \n",
       "4588            0.0             0.0               0.0                 0.0   \n",
       "4589            1.0             0.0               0.0                 0.0   \n",
       "4590            0.0             0.0               0.0                 0.0   \n",
       "4591            0.0             0.0               0.0                 0.0   \n",
       "4592            1.0             0.0               0.0                 0.0   \n",
       "4593            0.0             0.0               0.0                 0.0   \n",
       "4594            0.0             0.0               0.0                 0.0   \n",
       "4595            0.0             0.0               0.0                 0.0   \n",
       "4596            0.0             1.0               0.0                 0.0   \n",
       "4597            0.0             0.0               0.0                 0.0   \n",
       "4598            0.0             0.0               0.0                 0.0   \n",
       "4599            1.0             0.0               0.0                 0.0   \n",
       "4600            0.0             0.0               0.0                 0.0   \n",
       "\n",
       "      word_freq_order  word_freq_mail     ...       word_freq_re  \\\n",
       "0                 0.0             0.0     ...                0.0   \n",
       "1                 0.0             1.0     ...                0.0   \n",
       "2                 1.0             1.0     ...                1.0   \n",
       "3                 1.0             1.0     ...                0.0   \n",
       "4                 1.0             1.0     ...                0.0   \n",
       "5                 0.0             0.0     ...                0.0   \n",
       "6                 0.0             1.0     ...                0.0   \n",
       "7                 0.0             0.0     ...                0.0   \n",
       "8                 1.0             1.0     ...                0.0   \n",
       "9                 1.0             0.0     ...                0.0   \n",
       "10                0.0             1.0     ...                0.0   \n",
       "11                0.0             0.0     ...                0.0   \n",
       "12                0.0             0.0     ...                0.0   \n",
       "13                0.0             1.0     ...                0.0   \n",
       "14                0.0             1.0     ...                0.0   \n",
       "15                0.0             1.0     ...                0.0   \n",
       "16                0.0             0.0     ...                0.0   \n",
       "17                0.0             0.0     ...                0.0   \n",
       "18                0.0             0.0     ...                0.0   \n",
       "19                1.0             0.0     ...                0.0   \n",
       "20                0.0             0.0     ...                0.0   \n",
       "21                1.0             0.0     ...                0.0   \n",
       "22                0.0             0.0     ...                0.0   \n",
       "23                0.0             0.0     ...                0.0   \n",
       "24                0.0             0.0     ...                1.0   \n",
       "25                1.0             0.0     ...                0.0   \n",
       "26                0.0             0.0     ...                1.0   \n",
       "27                0.0             0.0     ...                0.0   \n",
       "28                0.0             0.0     ...                0.0   \n",
       "29                0.0             0.0     ...                0.0   \n",
       "...               ...             ...     ...                ...   \n",
       "4571              0.0             0.0     ...                0.0   \n",
       "4572              0.0             0.0     ...                0.0   \n",
       "4573              0.0             0.0     ...                1.0   \n",
       "4574              0.0             1.0     ...                0.0   \n",
       "4575              0.0             1.0     ...                1.0   \n",
       "4576              0.0             0.0     ...                1.0   \n",
       "4577              0.0             0.0     ...                0.0   \n",
       "4578              0.0             0.0     ...                1.0   \n",
       "4579              0.0             0.0     ...                0.0   \n",
       "4580              0.0             0.0     ...                0.0   \n",
       "4581              0.0             0.0     ...                0.0   \n",
       "4582              0.0             0.0     ...                0.0   \n",
       "4583              0.0             0.0     ...                1.0   \n",
       "4584              0.0             0.0     ...                1.0   \n",
       "4585              0.0             0.0     ...                0.0   \n",
       "4586              0.0             0.0     ...                0.0   \n",
       "4587              0.0             0.0     ...                0.0   \n",
       "4588              0.0             0.0     ...                1.0   \n",
       "4589              0.0             0.0     ...                0.0   \n",
       "4590              0.0             0.0     ...                0.0   \n",
       "4591              0.0             0.0     ...                0.0   \n",
       "4592              0.0             0.0     ...                1.0   \n",
       "4593              0.0             0.0     ...                0.0   \n",
       "4594              0.0             0.0     ...                0.0   \n",
       "4595              0.0             0.0     ...                0.0   \n",
       "4596              0.0             0.0     ...                1.0   \n",
       "4597              0.0             0.0     ...                0.0   \n",
       "4598              0.0             0.0     ...                0.0   \n",
       "4599              0.0             0.0     ...                0.0   \n",
       "4600              0.0             0.0     ...                1.0   \n",
       "\n",
       "      word_freq_edu  word_freq_table  word_freq_conference  char_freq_;  \\\n",
       "0               0.0              0.0                   0.0          0.0   \n",
       "1               0.0              0.0                   0.0          0.0   \n",
       "2               1.0              0.0                   0.0          1.0   \n",
       "3               0.0              0.0                   0.0          0.0   \n",
       "4               0.0              0.0                   0.0          0.0   \n",
       "5               0.0              0.0                   0.0          0.0   \n",
       "6               0.0              0.0                   0.0          0.0   \n",
       "7               0.0              0.0                   0.0          0.0   \n",
       "8               0.0              0.0                   0.0          0.0   \n",
       "9               0.0              0.0                   0.0          1.0   \n",
       "10              0.0              0.0                   0.0          0.0   \n",
       "11              0.0              0.0                   0.0          1.0   \n",
       "12              0.0              0.0                   0.0          0.0   \n",
       "13              0.0              0.0                   0.0          0.0   \n",
       "14              0.0              0.0                   0.0          0.0   \n",
       "15              0.0              0.0                   0.0          0.0   \n",
       "16              0.0              0.0                   0.0          0.0   \n",
       "17              0.0              0.0                   0.0          0.0   \n",
       "18              0.0              0.0                   0.0          0.0   \n",
       "19              0.0              0.0                   0.0          0.0   \n",
       "20              0.0              0.0                   0.0          0.0   \n",
       "21              0.0              0.0                   0.0          1.0   \n",
       "22              0.0              0.0                   0.0          1.0   \n",
       "23              0.0              0.0                   0.0          0.0   \n",
       "24              0.0              0.0                   0.0          0.0   \n",
       "25              0.0              0.0                   0.0          1.0   \n",
       "26              0.0              0.0                   0.0          0.0   \n",
       "27              0.0              0.0                   0.0          0.0   \n",
       "28              0.0              0.0                   0.0          0.0   \n",
       "29              0.0              0.0                   0.0          0.0   \n",
       "...             ...              ...                   ...          ...   \n",
       "4571            1.0              0.0                   0.0          0.0   \n",
       "4572            1.0              0.0                   0.0          0.0   \n",
       "4573            1.0              0.0                   0.0          1.0   \n",
       "4574            1.0              0.0                   0.0          0.0   \n",
       "4575            1.0              0.0                   0.0          0.0   \n",
       "4576            1.0              0.0                   0.0          0.0   \n",
       "4577            1.0              0.0                   0.0          0.0   \n",
       "4578            1.0              0.0                   0.0          0.0   \n",
       "4579            1.0              0.0                   0.0          1.0   \n",
       "4580            1.0              0.0                   0.0          0.0   \n",
       "4581            1.0              0.0                   0.0          0.0   \n",
       "4582            1.0              0.0                   0.0          0.0   \n",
       "4583            1.0              0.0                   0.0          0.0   \n",
       "4584            1.0              0.0                   0.0          0.0   \n",
       "4585            1.0              0.0                   0.0          0.0   \n",
       "4586            0.0              0.0                   0.0          0.0   \n",
       "4587            1.0              0.0                   0.0          0.0   \n",
       "4588            1.0              0.0                   0.0          0.0   \n",
       "4589            1.0              0.0                   0.0          0.0   \n",
       "4590            1.0              0.0                   0.0          0.0   \n",
       "4591            1.0              0.0                   0.0          0.0   \n",
       "4592            1.0              0.0                   0.0          0.0   \n",
       "4593            1.0              0.0                   0.0          0.0   \n",
       "4594            1.0              0.0                   0.0          0.0   \n",
       "4595            1.0              0.0                   0.0          0.0   \n",
       "4596            1.0              0.0                   0.0          0.0   \n",
       "4597            1.0              0.0                   0.0          0.0   \n",
       "4598            1.0              0.0                   0.0          1.0   \n",
       "4599            1.0              0.0                   0.0          0.0   \n",
       "4600            1.0              0.0                   0.0          0.0   \n",
       "\n",
       "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \n",
       "0             0.0          0.0          1.0          0.0          0.0  \n",
       "1             1.0          0.0          1.0          1.0          1.0  \n",
       "2             1.0          0.0          1.0          1.0          1.0  \n",
       "3             1.0          0.0          1.0          0.0          0.0  \n",
       "4             1.0          0.0          1.0          0.0          0.0  \n",
       "5             1.0          0.0          0.0          0.0          0.0  \n",
       "6             1.0          0.0          1.0          1.0          0.0  \n",
       "7             1.0          0.0          0.0          0.0          0.0  \n",
       "8             1.0          0.0          1.0          1.0          1.0  \n",
       "9             1.0          0.0          1.0          1.0          0.0  \n",
       "10            0.0          0.0          1.0          0.0          0.0  \n",
       "11            1.0          0.0          1.0          0.0          0.0  \n",
       "12            1.0          0.0          1.0          0.0          0.0  \n",
       "13            0.0          0.0          0.0          0.0          0.0  \n",
       "14            1.0          0.0          1.0          0.0          0.0  \n",
       "15            1.0          0.0          1.0          1.0          0.0  \n",
       "16            0.0          0.0          1.0          0.0          0.0  \n",
       "17            0.0          0.0          1.0          1.0          0.0  \n",
       "18            1.0          0.0          1.0          0.0          0.0  \n",
       "19            1.0          0.0          1.0          1.0          0.0  \n",
       "20            1.0          0.0          1.0          0.0          0.0  \n",
       "21            1.0          1.0          1.0          1.0          1.0  \n",
       "22            1.0          0.0          1.0          0.0          0.0  \n",
       "23            1.0          0.0          1.0          0.0          0.0  \n",
       "24            1.0          0.0          1.0          1.0          0.0  \n",
       "25            1.0          1.0          1.0          1.0          1.0  \n",
       "26            1.0          0.0          1.0          1.0          0.0  \n",
       "27            0.0          0.0          1.0          0.0          0.0  \n",
       "28            1.0          0.0          1.0          0.0          0.0  \n",
       "29            1.0          0.0          1.0          0.0          0.0  \n",
       "...           ...          ...          ...          ...          ...  \n",
       "4571          1.0          0.0          1.0          0.0          0.0  \n",
       "4572          1.0          0.0          0.0          0.0          0.0  \n",
       "4573          1.0          0.0          1.0          0.0          0.0  \n",
       "4574          1.0          0.0          0.0          0.0          0.0  \n",
       "4575          1.0          0.0          0.0          0.0          0.0  \n",
       "4576          1.0          0.0          0.0          0.0          0.0  \n",
       "4577          0.0          0.0          0.0          0.0          0.0  \n",
       "4578          0.0          1.0          0.0          0.0          0.0  \n",
       "4579          1.0          1.0          1.0          0.0          1.0  \n",
       "4580          0.0          0.0          0.0          0.0          0.0  \n",
       "4581          1.0          0.0          1.0          0.0          0.0  \n",
       "4582          0.0          0.0          0.0          0.0          0.0  \n",
       "4583          0.0          1.0          0.0          0.0          0.0  \n",
       "4584          1.0          0.0          1.0          0.0          0.0  \n",
       "4585          1.0          0.0          0.0          0.0          0.0  \n",
       "4586          1.0          0.0          0.0          0.0          1.0  \n",
       "4587          1.0          0.0          0.0          1.0          0.0  \n",
       "4588          0.0          0.0          0.0          0.0          0.0  \n",
       "4589          0.0          0.0          0.0          0.0          0.0  \n",
       "4590          1.0          0.0          0.0          0.0          1.0  \n",
       "4591          0.0          0.0          0.0          0.0          0.0  \n",
       "4592          1.0          0.0          0.0          0.0          0.0  \n",
       "4593          0.0          0.0          1.0          0.0          0.0  \n",
       "4594          1.0          0.0          0.0          0.0          0.0  \n",
       "4595          0.0          0.0          0.0          0.0          0.0  \n",
       "4596          1.0          0.0          0.0          0.0          0.0  \n",
       "4597          0.0          0.0          1.0          0.0          0.0  \n",
       "4598          1.0          0.0          0.0          0.0          0.0  \n",
       "4599          1.0          0.0          0.0          0.0          0.0  \n",
       "4600          0.0          0.0          1.0          0.0          0.0  \n",
       "\n",
       "[4601 rows x 54 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "X = spambase_binary.drop(columns='is_spam')\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Create a Pandas Series object `y` that contains only the label from `spambase_binary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "5       1.0\n",
       "6       1.0\n",
       "7       1.0\n",
       "8       1.0\n",
       "9       1.0\n",
       "10      1.0\n",
       "11      1.0\n",
       "12      1.0\n",
       "13      1.0\n",
       "14      1.0\n",
       "15      1.0\n",
       "16      1.0\n",
       "17      1.0\n",
       "18      1.0\n",
       "19      1.0\n",
       "20      1.0\n",
       "21      1.0\n",
       "22      1.0\n",
       "23      1.0\n",
       "24      1.0\n",
       "25      1.0\n",
       "26      1.0\n",
       "27      1.0\n",
       "28      1.0\n",
       "29      1.0\n",
       "       ... \n",
       "4571    0.0\n",
       "4572    0.0\n",
       "4573    0.0\n",
       "4574    0.0\n",
       "4575    0.0\n",
       "4576    0.0\n",
       "4577    0.0\n",
       "4578    0.0\n",
       "4579    0.0\n",
       "4580    0.0\n",
       "4581    0.0\n",
       "4582    0.0\n",
       "4583    0.0\n",
       "4584    0.0\n",
       "4585    0.0\n",
       "4586    0.0\n",
       "4587    0.0\n",
       "4588    0.0\n",
       "4589    0.0\n",
       "4590    0.0\n",
       "4591    0.0\n",
       "4592    0.0\n",
       "4593    0.0\n",
       "4594    0.0\n",
       "4595    0.0\n",
       "4596    0.0\n",
       "4597    0.0\n",
       "4598    0.0\n",
       "4599    0.0\n",
       "4600    0.0\n",
       "Length: 4601, dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "# y = pd.Series(list(spambase_binary.values()))\n",
    "# y = pd.Series(list(spambase_binary.index.values)[0:5])\n",
    "y = pd.Series(list(true_labels))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Display the dimensionality (i.e. `shape`) of each of the two arrays. *Hint:* The shape of `X` and `y` should be `(4601, 54)` and `(4601,)` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 54)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes he\n",
    "X.shape\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 7 ==========\n",
    "\n",
    "Now we want to train a Multinomial Naive Bayes classifier. Initialise a `MultinomialNB` object and [`fit`](http://scikit-learn.org/0.19/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit) the classifier using the `X` and `y` arrays extracted in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the classifier by looking at the classification accuracy, and the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix). \n",
    "\n",
    "Scikit-learn model objects have built in scoring methods. The default [`score` method for `MultinomialNB`](http://scikit-learn.org/0.19/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.score) estimates the classification accuracy score. Alternatively, you can compute the prediction for the training data and make use of the [`accuracy_score`](http://scikit-learn.org/0.19/modules/generated/sklearn.metrics.accuracy_score.html) function (that is in fact what the classifier's `score()` method does under the hood).\n",
    "\n",
    "Scikit-learn also has a [`confusion_matrix`](http://scikit-learn.org/0.19/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) implementation which returns a numpy array (square matrix) of dimensionality `K`, where `K` is the number of classes (2 in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 8 ========== "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Display the log-prior probabilities for each class. *Hint:* use tab-completion to figure out which attribute of the `MultinomialNB` structure you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50094918, -0.93129074])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "clf.class_log_prior_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Predict the output of the classifier by using the training data as input. *Hint*: make use of the `predict` method of the `MultinomialNB` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Compute the classification accuracy on the training data by either using the `accuracy_score` metric or the `score` method of the `MultinomialNB`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8924146924581613"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "clf.score(X, y)\n",
    "# accuracy_score(true_labels, clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Compute the resulting confusion_matrix by using the builtin scikit-learn class and display the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2412,  376],\n",
       "       [ 119, 1694]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "cm = confusion_matrix(y, clf.predict(X))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Normalise the produced confusion matrix by the true class and display the result. In other words, the matrix should show you what proportion of `Ham` emails were predicted as `Ham`/`Spam` and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52423386, 0.08172136],\n",
       "       [0.02586394, 0.36818083]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "cm / 4601"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** By making use of the `plot_confusion_matrix` provided below, visualise the normalised confusion matrix. Plot the appropriate labels on both axes by making use of the `classes` input argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "plot_confusion_matrix(cm, classes=None, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 9 ==========\n",
    "\n",
    "Study the output produced, most importantly the percentages of correctly and incorrectly classified instances. You probably will notice that your classifer does rather well despite making a very strong assumption on the form of the data. If we didn't make this assumption, what would be the main practical problems? *Hint*: If you've forgotten the assumption of the Naive Bayes model, check wikipedia and/or sklearn documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 10 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empirical log probability of input features given a class $P\\left(x_i  |  y\\right)$ is given by the attribute `feature_log_prob` of the classifier. For each feature there are two such conditional probabilities, one for each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** What dimensionality do you expect the `feature_log_prob_` array to have? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Inspect the log probabilities of the features. Verify that it has the expected dimensionality (i.e. `shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 54)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "clf.feature_log_prob_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Create a list of the names of the features that have higher log probability when the email is `Ham` than `Spam` i.e. what features imply an email is more likely to be `Ham`? *Hint:* There are a many ways to do this. Try it on your own then, if you get stuck, you can do it using index numbers (look up [`np.argwhere`](http://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.argwhere.html)), or using a boolean mask (look up [pandas indexing](http://pandas.pydata.org/pandas-docs/version/0.23.4/indexing.html)). The column names of a Pandas DataFrame are contained in the `columns` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 11 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final part of this section we will now pretend we are spammers wishing to fool a spam checking system based on NaÃ¯ve Bayes into classifying a spam e-mail as ham (i.e. a valid e-mail). For this we will use a test set consisting of just one data point (i.e. e-mail). This tiny dataset is called `spambase_test` and has already been pre-processed for you which means that the redundant attributes have been removed and word frequencies have been replaced by word presence/absence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Load `./datasets/spambase_test.csv` dataset into a new pandas structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0                  1              1             0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              1               0                 0                   0   \n",
       "\n",
       "   word_freq_order  word_freq_mail   ...     word_freq_edu  word_freq_table  \\\n",
       "0                0               0   ...                 0                0   \n",
       "\n",
       "   word_freq_conference  char_freq_;  char_freq_(  char_freq_[  char_freq_!  \\\n",
       "0                     0            0            0            0            1   \n",
       "\n",
       "   char_freq_$  char_freq_#  is_spam  \n",
       "0            0            0        1  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'spambase_test.csv')\n",
    "spambase_test = pd.read_csv(data_path, delimiter = ',')\n",
    "# ./datasets/spambase_test.csv\n",
    "spambase_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Use `spambase_test` to create a pandas DataFrame object X_test, contatining the test features, and pandas Series object y_test, containing the test outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Feed the input features into the classifier and compare the outcome to the true label. Make sure you don't feed the target into the classifier as you will receive an error (why?). Does the classifer classify the spam e-mail correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Pick one (perhaps random) attribute that has higher probability for the ham class (using your feature names in Question 10c) and set the corresponding value in `X_test` to 1. Now predict the new outcome. Has it changed? If not, keep modifying more attributes until you have achieved the desired outcome (i.e. model classifies the e-mail as ham)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 12 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is an extension for people keen to learn more advanced plotting.** We'll be happy to discuss your conclusions in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Create a plot of the spam/ham log probabilities for all of the features. This will help you find the spammiest/hammiest words to use in your emails! *Hint*: you can do this however you like, but try 'adapting' [this matplotlib demo](https://matplotlib.org/2.2.3/gallery/statistics/barchart_demo.html?highlight=bar%20chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** The features are in the order they appear in the dataset. Can you order them by probability of being `Ham`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** What about ordering by the absolute difference between `Ham` and `Spam` log probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
